"""
AI ê¸°ë°˜ 10-K ë¶„ì„ê¸°

Claudeê°€ ì§ì ‘ 10-Kë¥¼ ì½ê³  ë¶„ì„í•©ë‹ˆë‹¤.
- Regex íŒ¨í„´ ë§¤ì¹­ X
- AIê°€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ

ë¶„ì„ í•­ëª©:
1. ê²½ìŸ í™˜ê²½ (ëˆ„ê°€ ê²½ìŸì‚¬? ì‹œì¥ ì ìœ ìœ¨ì€?)
2. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë³€í™”
3. ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ë¡œë“œë§µ
4. ê³µê¸‰ë§ êµ¬ì¡° ë° ë¦¬ìŠ¤í¬
5. ê·œì œ/ì§€ì •í•™ ì˜í–¥
6. ê²½ì˜ì§„ ì „ë§ (êµ¬ì²´ì  ìˆ«ì)
7. í•µì‹¬ ë¦¬ìŠ¤í¬ (ìƒˆë¡œ ì¶”ê°€ëœ ê²ƒ)
8. ì¬ë¬´ ì „ëµ (CAPEX, R&D ê³„íš)
"""
import json
import os


class AI10KAnalyzer:
    """AI ê¸°ë°˜ 10-K ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.analysis_prompts = self.define_prompts()
    
    def define_prompts(self):
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì •ì˜"""
        
        return {
            'business_model': """
ì´ íšŒì‚¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (êµ¬ì²´ì  ì´ë¦„ê³¼ ë§¤ì¶œ ë¹„ì¤‘)
2. ìˆ˜ìµ ëª¨ë¸ì€? (ê´‘ê³ , êµ¬ë…, ì œí’ˆ íŒë§¤, ìˆ˜ìˆ˜ë£Œ ë“±)
3. íƒ€ê²Ÿ ê³ ê°ì€?
4. í•µì‹¬ ì°¨ë³„í™” ìš”ì†ŒëŠ”?
5. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ì¤‘ìš”í•œ ë³€í™”ê°€ ìˆë‚˜ìš”?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "products": [{"name": "...", "revenue_share": "...%", "description": "..."}],
  "revenue_model": ["..."],
  "target_customers": ["..."],
  "differentiation": ["..."],
  "changes": ["..."]
}
""",
            
            'competition': """
ê²½ìŸ í™˜ê²½ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ê²½ìŸì‚¬ëŠ”? (êµ¬ì²´ì  íšŒì‚¬ëª…)
2. ì‹œì¥ ì ìœ ìœ¨ì€? (ì´ íšŒì‚¬ vs ê²½ìŸì‚¬)
3. ê²½ìŸ ìš°ìœ„ëŠ”?
4. ê²½ìŸ ì—´ìœ„ëŠ”?
5. ì‹œì¥ êµ¬ì¡° ë³€í™”?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "competitors": [{"name": "...", "market_share": "...%", "strength": "..."}],
  "our_market_share": "...%",
  "competitive_advantages": ["..."],
  "competitive_weaknesses": ["..."],
  "market_trends": ["..."]
}
""",
            
            'supply_chain': """
ê³µê¸‰ë§ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. í•µì‹¬ ê³µê¸‰ì—…ì²´ëŠ”? (sole supplier?)
2. ê³µê¸‰ë§ ë¦¬ìŠ¤í¬ëŠ”?
3. ì œì¡° ì „ëµ? (ìì²´ ì œì¡° vs ì™¸ì£¼)
4. ê³µê¸‰ë§ ê´€ë ¨ íˆ¬ì ê³„íš?
5. ê³µê¸‰ë§ ì´ìŠˆê°€ ë§¤ì¶œ/ë¹„ìš©ì— ë¯¸ì¹œ ì˜í–¥?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "key_suppliers": [{"name": "...", "role": "...", "dependency": "sole/primary/secondary"}],
  "risks": ["..."],
  "manufacturing_strategy": "...",
  "investments": ["..."],
  "financial_impact": "..."
}
""",
            
            'forward_guidance': """
ê²½ì˜ì§„ ì „ë§ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë§¤ì¶œ ì„±ì¥ë¥  ì „ë§? (êµ¬ì²´ì  %ë‚˜ ë²”ìœ„)
2. ë§ˆì§„ ì „ë§?
3. CAPEX ê³„íš?
4. ì‹ ì œí’ˆ ì¶œì‹œ ì¼ì •?
5. ì‹œì¥/ê³ ê° í™•ëŒ€ ê³„íš?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "revenue_growth": "...%",
  "margin_outlook": "...",
  "capex_plan": "...",
  "new_products": [{"name": "...", "launch_date": "..."}],
  "expansion_plans": ["..."]
}
""",
            
            'risks': """
í•µì‹¬ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ìƒˆë¡œ ì¶”ê°€ëœ ë¦¬ìŠ¤í¬ëŠ”?
2. ê°€ì¥ ì¤‘ìš”í•œ ë¦¬ìŠ¤í¬ Top 5ëŠ”?
3. ê° ë¦¬ìŠ¤í¬ì˜ ì¬ë¬´ì  ì˜í–¥ì€?
4. ë¦¬ìŠ¤í¬ ì™„í™” ê³„íšì€?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "new_risks": ["..."],
  "top_5_risks": [{"risk": "...", "impact": "...", "mitigation": "..."}]
}
""",
            
            'regulatory': """
ê·œì œ/ì§€ì •í•™ ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ê´€ì„¸/ë¬´ì—­ ê·œì œ ì˜í–¥? (êµ¬ì²´ì  ê¸ˆì•¡)
2. ì¤‘êµ­/EU ë“± íŠ¹ì • ì§€ì—­ ë¦¬ìŠ¤í¬?
3. ê·œì œ ë³€í™” ëŒ€ì‘ ê³„íš?
4. ì§€ì •í•™ ë¦¬ìŠ¤í¬ë¡œ ì¸í•œ ì „ëµ ë³€í™”?

JSON í˜•íƒœë¡œ ë‹µë³€:
{
  "tariff_impact": "...",
  "regional_risks": [{"region": "...", "issue": "...", "impact": "..."}],
  "compliance_plan": ["..."],
  "strategic_changes": ["..."]
}
""",
        }
    
    def create_analysis_script(self, ticker, section_name):
        """
        ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        
        ì´ í•¨ìˆ˜ëŠ” ì‹¤ì œë¡œëŠ” ì‚¬ìš©ì(ë‹¹ì‹ )ê°€ ì§ì ‘ ì‹¤í–‰í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        Claude APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ë‹¹ì‹ ì´ ì´ ì°½ì—ì„œ ì§ì ‘ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        
        filename = f'data/section_{ticker}_{section_name}.txt'
        
        if not os.path.exists(filename):
            return None
        
        with open(filename, 'r', encoding='utf-8') as f:
            text = f.read()
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
        max_length = 100000  # ì•½ 100KB
        
        if len(text) > max_length:
            # ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ (ì• 50%, ë’¤ 50%)
            half = max_length // 2
            text = text[:half] + "\n\n[... ì¤‘ê°„ ìƒëµ ...]\n\n" + text[-half:]
        
        return {
            'ticker': ticker,
            'section': section_name,
            'text_length': len(text),
            'text': text,
            'prompts': self.analysis_prompts
        }
    
    def generate_analysis_tasks(self, tickers):
        """ë¶„ì„ ì‘ì—… ìƒì„±"""
        
        print("="*80)
        print("ğŸ¤– AI ê¸°ë°˜ 10-K ë¶„ì„ ì‘ì—… ìƒì„±")
        print("="*80)
        print()
        print("ì „ëµ:")
        print("  1. Claudeê°€ ì§ì ‘ ê° ì„¹ì…˜ ì½ê¸°")
        print("  2. êµ¬ì¡°í™”ëœ ì§ˆë¬¸ì— JSONìœ¼ë¡œ ë‹µë³€")
        print("  3. Regex íŒ¨í„´ ë§¤ì¹­ ì—†ìŒ")
        print()
        
        tasks = []
        
        for ticker in tickers:
            print(f"\n{'='*80}")
            print(f"ğŸ“Š {ticker} ë¶„ì„ ì‘ì—… ìƒì„±")
            print('-'*80)
            
            # Item 1: ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸, ê²½ìŸ í™˜ê²½
            item1_task = self.create_analysis_script(ticker, 'item_1_business')
            if item1_task:
                item1_task['analysis_type'] = ['business_model', 'competition', 'supply_chain']
                tasks.append(item1_task)
                print(f"   âœ… Item 1 (Business): {item1_task['text_length']:,} chars")
            
            # Item 1A: ë¦¬ìŠ¤í¬, ê·œì œ
            item1a_task = self.create_analysis_script(ticker, 'item_1a_risk_factors')
            if item1a_task:
                item1a_task['analysis_type'] = ['risks', 'regulatory']
                tasks.append(item1a_task)
                print(f"   âœ… Item 1A (Risk): {item1a_task['text_length']:,} chars")
            
            # Item 7: ì „ë§, ì¬ë¬´ ì „ëµ
            item7_task = self.create_analysis_script(ticker, 'item_7_mda')
            if item7_task:
                item7_task['analysis_type'] = ['forward_guidance', 'supply_chain']
                tasks.append(item7_task)
                print(f"   âœ… Item 7 (MD&A): {item7_task['text_length']:,} chars")
        
        # ì €ì¥
        with open('data/ai_analysis_tasks.json', 'w', encoding='utf-8') as f:
            # í…ìŠ¤íŠ¸ëŠ” ë„ˆë¬´ ì»¤ì„œ ì œì™¸
            tasks_meta = [
                {
                    'ticker': t['ticker'],
                    'section': t['section'],
                    'text_length': t['text_length'],
                    'analysis_type': t['analysis_type']
                }
                for t in tasks
            ]
            json.dump(tasks_meta, f, indent=2)
        
        print(f"\n{'='*80}")
        print(f"âœ… ì´ {len(tasks)}ê°œ ë¶„ì„ ì‘ì—… ìƒì„±")
        print("="*80)
        
        return tasks


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    analyzer = AI10KAnalyzer()
    
    STOCKS = ['AAPL', 'META', 'NVDA', 'AMZN', 'TSLA']
    
    tasks = analyzer.generate_analysis_tasks(STOCKS)
    
    print(f"\n{'='*80}")
    print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„: AI ë¶„ì„ ì‹¤í–‰")
    print('='*80)
    print()
    print("ë°©ë²• 1: ì´ ì°½ì—ì„œ ì§ì ‘ ë¶„ì„")
    print("  - ê° ì¢…ëª©/ì„¹ì…˜ì„ Claude(ì €)ì—ê²Œ ì§ì ‘ ë³´ì—¬ì£¼ê¸°")
    print("  - í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ ì œê³µ")
    print("  - JSON ê²°ê³¼ ë°›ì•„ì„œ ì €ì¥")
    print()
    print("ë°©ë²• 2: Claude API ì‚¬ìš© (ë¹„ìš© ë°œìƒ)")
    print("  - anthropic Python SDK ì‚¬ìš©")
    print("  - ìë™í™” ê°€ëŠ¥")
    print("  - í•˜ì§€ë§Œ ë¹„ìš© ë°œìƒ")
    print()
    print("ì¶”ì²œ: ë°©ë²• 1 (ì§ì ‘ ë¶„ì„)")
    print("  â†’ 5ê°œ ì¢…ëª© Ã— 3ê°œ ì„¹ì…˜ = 15ê°œ ë¶„ì„")
    print("  â†’ ê° 5-10ë¶„ = ì´ 2-3ì‹œê°„")
    print("  â†’ 100% ì •í™•ë„, ë¹„ìš© 0")
    print()
    
    # ì²« ë²ˆì§¸ ì‘ì—… ìƒ˜í”Œ
    if tasks:
        first_task = tasks[0]
        
        print(f"{'='*80}")
        print(f"ğŸ“„ ìƒ˜í”Œ ë¶„ì„ ì‘ì—…: {first_task['ticker']} - {first_task['section']}")
        print('='*80)
        print()
        print("ë¶„ì„ í•­ëª©:")
        for analysis_type in first_task['analysis_type']:
            print(f"  - {analysis_type}")
        print()
        print("í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:")
        print('-'*80)
        print(first_task['prompts']['business_model'])
        print()
        print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {first_task['text_length']:,} chars")
        print()
        
        # í…ìŠ¤íŠ¸ ìƒ˜í”Œ ì €ì¥
        sample_file = f"data/analysis_sample_{first_task['ticker']}_{first_task['section']}.txt"
        with open(sample_file, 'w', encoding='utf-8') as f:
            f.write(f"Ticker: {first_task['ticker']}\n")
            f.write(f"Section: {first_task['section']}\n")
            f.write(f"Analysis Types: {', '.join(first_task['analysis_type'])}\n")
            f.write("\n" + "="*80 + "\n")
            f.write("TEXT:\n")
            f.write("="*80 + "\n\n")
            f.write(first_task['text'][:5000])  # ì²˜ìŒ 5000ìë§Œ
            f.write("\n\n[... continues ...]")
        
        print(f"âœ… ìƒ˜í”Œ ì €ì¥: {sample_file}")
    
    print(f"\n{'='*80}")
    print("ğŸ’¡ ì´ì œ ì§„ì§œ AI ê¸°ë°˜ ë¶„ì„!")
    print("="*80)


if __name__ == "__main__":
    main()

