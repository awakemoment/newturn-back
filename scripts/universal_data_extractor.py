"""
ë²”ìš© 10-K ë°ì´í„° ì¶”ì¶œê¸°

ëª©í‘œ: ìˆ«ìê°€ ì•„ë‹Œ ì •ì„±ì  ì¸ì‚¬ì´íŠ¸ 100% ì¶”ì¶œ

ì¶”ì¶œ ëŒ€ìƒ:
1. ê²½ìŸì‚¬ ì–¸ê¸‰ ë° ì‹œì¥ ì ìœ ìœ¨
2. ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ë¡œë“œë§µ
3. ê³µê¸‰ë§ êµ¬ì²´ ì •ë³´
4. ê²½ì˜ì§„ ì „ë§ ë° ê°€ì´ë˜ìŠ¤
5. ê³ ê° ì§‘ì¤‘ë„
6. ì§€ì •í•™/ê·œì œ ì˜í–¥
7. í•µì‹¬ íŒŒíŠ¸ë„ˆì‹­
8. M&A ê³„íš
9. êµ¬ì¡°ì¡°ì •/ë¹„ìš© ì ˆê°
10. ì‹ ê·œ ë¦¬ìŠ¤í¬

ì¶”ì¶œ ë°©ë²•:
- íŒ¨í„´ ë§¤ì¹­
- ë¬¸ë§¥ ê¸°ë°˜ ì¶”ì¶œ
- ì—”í‹°í‹° ì¸ì‹
- ê´€ê³„ ì¶”ì¶œ
"""
import re
import json


class UniversalDataExtractor:
    """ë²”ìš© ë°ì´í„° ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.patterns = self.define_patterns()
    
    def define_patterns(self):
        """ì¶”ì¶œ íŒ¨í„´ ì •ì˜"""
        
        return {
            # 1. ê²½ìŸì‚¬ ì–¸ê¸‰
            'competitors': {
                'patterns': [
                    r'([\w\s]+)\s+(?:is|are|has|have)\s+(?:our|a|the)\s+(?:main|primary|key|major)?\s*(?:competitor|competition)',
                    r'(?:compete|competing)\s+(?:with|against)\s+([\w\s,&]+)',
                    r'([\w]+)(?:\'s)?\s+market share',
                    r'versus\s+([\w\s]+)',
                ],
                'keywords': ['Samsung', 'Huawei', 'AMD', 'Intel', 'AWS', 'Azure', 'TikTok', 'BYD']
            },
            
            # 2. ì‹œì¥ ì ìœ ìœ¨
            'market_share': {
                'patterns': [
                    r'market share.*?(\d+(?:\.\d+)?)\s*(?:%|percent|percentage)',
                    r'(\d+(?:\.\d+)?)\s*(?:%|percent)\s+(?:of|market|share)',
                    r'(?:declined|increased|grew)\s+(?:from|to)\s+(\d+)\s*%\s+to\s+(\d+)\s*%',
                ],
            },
            
            # 3. ì‹ ì œí’ˆ ë¡œë“œë§µ
            'product_roadmap': {
                'patterns': [
                    r'(?:expect to|plan to|will)\s+(?:launch|introduce|release)\s+([\w\s]+)',
                    r'(?:launching|releasing)\s+([\w\s]+)\s+in\s+(Q[1-4]|[Jj]anuary|[Ff]ebruary|202\d)',
                    r'new product.*?([\w\s]+)',
                ],
                'keywords': ['launch', 'introduce', 'release', 'unveil', 'announce']
            },
            
            # 4. ê³µê¸‰ë§ êµ¬ì²´ ì •ë³´
            'supply_chain': {
                'patterns': [
                    r'([\w\s]+)\s+(?:is|are)\s+(?:our|the)\s+(?:sole|single|primary|main)\s+(?:supplier|source|manufacturer)',
                    r'(?:sole|single)\s+source.*?([\w\s]+)',
                    r'supply\s+(?:constraint|shortage|disruption).*?(?:cost|impact|loss).*?\$?([\d,\.]+)\s*(?:billion|million)',
                ],
            },
            
            # 5. ê²½ì˜ì§„ ì „ë§ (Forward-looking)
            'management_guidance': {
                'patterns': [
                    r'(?:expect|anticipate|forecast|project|plan)\s+(?:to|that)?\s*.{0,100}?(\d+(?:\.\d+)?)\s*(?:%|percent)',
                    r'guidance.*?(\d+(?:\.\d+)?)\s*(?:%|percent)',
                    r'(?:will|should)\s+(?:grow|increase|decline)\s+(?:by\s+)?(\d+(?:\.\d+)?)\s*(?:%|percent)',
                ],
                'keywords': ['expect', 'anticipate', 'forecast', 'guidance', 'outlook', 'project']
            },
            
            # 6. ê³ ê° ì§‘ì¤‘ë„
            'customer_concentration': {
                'patterns': [
                    r'(?:top|largest)\s+(\d+)\s+customer.*?(?:account|represent).*?(\d+)\s*(?:%|percent)',
                    r'(\d+)\s*%.*?(?:from|by)\s+(?:top|largest|single)\s+customer',
                ],
            },
            
            # 7. ì§€ì •í•™/ê´€ì„¸ ì˜í–¥
            'geopolitical_impact': {
                'patterns': [
                    r'tariff.*?(?:\$|cost|impact).*?([\d,\.]+)\s*(?:billion|million)',
                    r'(?:China|Chinese|trade)\s+(?:restriction|ban|sanction|tariff).*?(?:impact|cost|loss)',
                    r'export\s+control.*?(?:impact|affect|limit)',
                ],
                'keywords': ['tariff', 'China', 'export control', 'sanction', 'trade war', 'geopolitical']
            },
            
            # 8. R&D ì§‘ì¤‘ ë¶„ì•¼
            'rd_focus': {
                'patterns': [
                    r'R&D.*?(?:focus|invest|spend).*?(?:on|in)\s+([\w\s,]+)',
                    r'(?:developing|building|creating)\s+([\w\s]+)\s+(?:technology|product|platform)',
                ],
                'keywords': ['AI', 'machine learning', 'autonomous', 'quantum', 'AR/VR', 'metaverse']
            },
            
            # 9. M&A ë° íˆ¬ì
            'ma_activity': {
                'patterns': [
                    r'(?:acquired|acquisition of)\s+([\w\s\.]+)\s+(?:for|in)\s+\$?([\d,\.]+)\s*(?:billion|million)',
                    r'invest(?:ed|ment)?\s+\$?([\d,\.]+)\s*(?:billion|million)\s+in\s+([\w\s]+)',
                ],
            },
            
            # 10. êµ¬ì¡°ì¡°ì •/ë¹„ìš© ì ˆê°
            'restructuring': {
                'patterns': [
                    r'(?:layoff|restructur|cost\s+reduction|headcount\s+reduction).*?(\d+(?:,\d+)?)\s+(?:employee|people|position)',
                    r'(?:save|reduce|cut)\s+(?:cost|expense).*?\$?([\d,\.]+)\s*(?:billion|million)',
                ],
                'keywords': ['layoff', 'restructuring', 'cost reduction', 'efficiency']
            },
        }
    
    def extract_from_text(self, text, ticker):
        """í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        results = {
            'ticker': ticker,
            'extracted': {}
        }
        
        for category, config in self.patterns.items():
            findings = []
            
            # íŒ¨í„´ ë§¤ì¹­
            for pattern in config.get('patterns', []):
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    # ë§¤ì¹˜ëœ ë¬¸ì¥ ì „ì²´ ì¶”ì¶œ
                    start = max(0, match.start() - 100)
                    end = min(len(text), match.end() + 100)
                    context = text[start:end]
                    
                    findings.append({
                        'matched': match.group(0),
                        'context': context.strip(),
                        'position': match.start()
                    })
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ
            if 'keywords' in config:
                for keyword in config['keywords']:
                    pattern = r'.{0,150}' + re.escape(keyword) + r'.{0,150}'
                    matches = re.finditer(pattern, text, re.IGNORECASE)
                    for match in matches:
                        findings.append({
                            'keyword': keyword,
                            'context': match.group(0).strip(),
                            'position': match.start()
                        })
            
            # ì¤‘ë³µ ì œê±° (ê°™ì€ ìœ„ì¹˜ ê·¼ì²˜)
            unique_findings = []
            positions = set()
            
            for finding in findings[:50]:  # ìµœëŒ€ 50ê°œ
                pos = finding.get('position', 0)
                # 500ì ì´ë‚´ ì¤‘ë³µ ì œê±°
                if not any(abs(pos - p) < 500 for p in positions):
                    unique_findings.append(finding)
                    positions.add(pos)
            
            results['extracted'][category] = unique_findings[:10]  # ê° ì¹´í…Œê³ ë¦¬ ìµœëŒ€ 10ê°œ
        
        return results
    
    def extract_all_stocks(self, tickers):
        """ëª¨ë“  ì¢…ëª© ì¶”ì¶œ"""
        
        print("="*80)
        print("ğŸ”¬ ë²”ìš© ë°ì´í„° ì¶”ì¶œê¸° ì‹¤í–‰")
        print("="*80)
        print()
        print("ëª©í‘œ: 10-K ë‚´ ëª¨ë“  ì •ì„±ì  ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ")
        print("     (ìˆ«ì í…Œì´ë¸”ì´ ì•„ë‹Œ ë¬¸ì¥/ë¬¸ë§¥ ì •ë³´)")
        print()
        
        all_results = {}
        
        for ticker in tickers:
            print(f"\n{'='*80}")
            print(f"ğŸ“Š {ticker} ì¶”ì¶œ ì¤‘...")
            print('-'*80)
            
            # Item 7 (MD&A) ì½ê¸°
            filename = f'data/section_{ticker}_item_7_mda.txt'
            
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    text = f.read()
                
                # ì¶”ì¶œ
                result = self.extract_from_text(text, ticker)
                
                # ê²°ê³¼ ìš”ì•½
                total_findings = sum(len(v) for v in result['extracted'].values())
                
                print(f"   âœ… ì´ {total_findings}ê°œ ì¸ì‚¬ì´íŠ¸ ë°œê²¬")
                
                # ì¹´í…Œê³ ë¦¬ë³„ ë¯¸ë¦¬ë³´ê¸°
                for category, findings in result['extracted'].items():
                    if findings:
                        print(f"      {category}: {len(findings)}ê°œ")
                
                all_results[ticker] = result
                
            except FileNotFoundError:
                print(f"   âŒ íŒŒì¼ ì—†ìŒ")
                all_results[ticker] = {'error': 'No file'}
        
        # ì €ì¥
        with open('data/universal_extraction_results.json', 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"\n{'='*80}")
        print("âœ… ì €ì¥: data/universal_extraction_results.json")
        print("="*80)
        
        return all_results


if __name__ == "__main__":
    extractor = UniversalDataExtractor()
    
    STOCKS = ['AAPL', 'META', 'NVDA', 'AMZN', 'TSLA']
    
    results = extractor.extract_all_stocks(STOCKS)
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\n{'='*80}")
    print("ğŸ“‹ ìƒ˜í”Œ ì¶”ì¶œ ê²°ê³¼ (AAPL)")
    print('='*80)
    
    if 'AAPL' in results:
        aapl = results['AAPL']
        
        for category, findings in aapl['extracted'].items():
            if findings:
                print(f"\nğŸ” {category}:")
                for i, finding in enumerate(findings[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ
                    context = finding.get('context', finding.get('matched', ''))
                    print(f"   {i}. {context[:150]}...")
    
    print(f"\n{'='*80}")
    print("ğŸ’¡ ì´ì œ ìš°ë¦¬ëŠ”:")
    print("="*80)
    print("  âœ… ê²½ìŸì‚¬ ì–¸ê¸‰ ìë™ ì¶”ì¶œ")
    print("  âœ… ì‹ ì œí’ˆ ë¡œë“œë§µ ë°œê²¬")
    print("  âœ… ê³µê¸‰ë§ ë¦¬ìŠ¤í¬ êµ¬ì²´í™”")
    print("  âœ… ê²½ì˜ì§„ ì „ë§ íŒŒì•…")
    print("  âœ… ì§€ì •í•™ ì˜í–¥ ì¶”ì ")
    print()
    print("â†’ ì´ê²ƒì´ ì§„ì§œ ì°¨ë³„í™”! ğŸš€")
    print("="*80)

