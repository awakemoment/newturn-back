"""
TSLA 10-K ìˆ˜ì§‘ ìˆ˜ì •

ë¬¸ì œ: 10-K/AëŠ” ìˆ˜ì •ë³¸ì´ë¼ ì „ì²´ ë‚´ìš©ì´ ì—†ì„ ìˆ˜ ìˆìŒ
í•´ê²°: 10-K (ì›ë³¸) ìš°ì„ , ì—†ìœ¼ë©´ 10-K/A
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import requests
from bs4 import BeautifulSoup
import time
from ixbrl_parser import iXBRLParser


def get_tsla_original_10k():
    """TSLA ì›ë³¸ 10-K ì°¾ê¸° (10-K/A ì œì™¸)"""
    
    BASE_URL = "https://www.sec.gov"
    headers = {
        'User-Agent': 'Newturn Investment Platform contact@newturn.ai',
        'Accept-Encoding': 'gzip, deflate',
        'Host': 'www.sec.gov'
    }
    
    cik = "0001318605"
    ticker = "TSLA"
    
    print("="*80)
    print("ğŸ” TSLA ì›ë³¸ 10-K ì°¾ê¸°")
    print("="*80)
    
    # ìµœê·¼ 10ê°œ Filing í™•ì¸
    url = f"{BASE_URL}/cgi-bin/browse-edgar"
    params = {
        'action': 'getcompany',
        'CIK': cik,
        'type': '10-K',
        'dateb': '',
        'owner': 'exclude',
        'count': '10',  # ìµœê·¼ 10ê°œ
    }
    
    response = requests.get(url, params=params, headers=headers)
    time.sleep(0.11)
    
    soup = BeautifulSoup(response.content, 'html.parser')
    table = soup.find('table', class_='tableFile2')
    
    if not table:
        print("âŒ No table")
        return None
    
    rows = table.find_all('tr')[1:]
    
    print(f"\nìµœê·¼ 10ê°œ Filing:")
    
    original_10k = None
    
    for i, row in enumerate(rows, 1):
        cells = row.find_all('td')
        filing_type = cells[0].text.strip()
        filing_date = cells[3].text.strip()
        
        print(f"  {i}. {filing_type:10s} - {filing_date}")
        
        # 10-K (ì›ë³¸) ìš°ì„  ì„ íƒ
        if filing_type == '10-K' and not original_10k:
            original_10k = row
            print(f"     âœ… ì›ë³¸ 10-K ë°œê²¬!")
    
    if not original_10k:
        print("\nâš ï¸ ì›ë³¸ 10-K ì—†ìŒ. 10-K/A ì‚¬ìš©...")
        # 10-K/Aë¼ë„ ì‚¬ìš©
        for row in rows:
            cells = row.find_all('td')
            filing_type = cells[0].text.strip()
            if filing_type == '10-K/A':
                original_10k = row
                print(f"  10-K/A ì‚¬ìš©: {cells[3].text.strip()}")
                break
    
    if not original_10k:
        print("âŒ 10-Kë„ 10-K/Aë„ ì—†ìŒ")
        return None
    
    # Documents ë²„íŠ¼
    doc_button = original_10k.find('a', {'id': 'documentsbutton'})
    if not doc_button:
        print("âŒ No documents button")
        return None
    
    filing_date = original_10k.find_all('td')[3].text.strip()
    documents_url = BASE_URL + doc_button['href']
    
    print(f"\nâœ… Documents: {documents_url}")
    
    # Documents í˜ì´ì§€ì—ì„œ HTML íŒŒì¼ ì°¾ê¸°
    response2 = requests.get(documents_url, headers=headers)
    time.sleep(0.11)
    
    soup2 = BeautifulSoup(response2.content, 'html.parser')
    table2 = soup2.find('table', class_='tableFile')
    
    if not table2:
        print("âŒ No documents table")
        return None
    
    # 10-K ë¬¸ì„œ ì°¾ê¸°
    for row in table2.find_all('tr')[1:]:
        cells = row.find_all('td')
        if len(cells) >= 4:
            doc_type = cells[3].text.strip()
            
            if doc_type in ['10-K', '10-K/A']:
                link = cells[2].find('a')
                if link:
                    href = link.get('href', '')
                    
                    if 'ix?doc=' in href:
                        actual_path = href.split('ix?doc=')[1]
                        doc_url = BASE_URL + actual_path
                    else:
                        doc_url = BASE_URL + href
                    
                    print(f"âœ… 10-K URL: {doc_url}")
                    
                    return {
                        'ticker': ticker,
                        'cik': cik,
                        'filing_date': filing_date,
                        'document_url': doc_url,
                    }
    
    return None


if __name__ == "__main__":
    metadata = get_tsla_original_10k()
    
    if metadata:
        print(f"\n{'='*80}")
        print("ğŸ“¥ TSLA 10-K ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±")
        print('='*80)
        
        parser = iXBRLParser()
        
        # ë‹¤ìš´ë¡œë“œ
        html = parser.download_10k_html(metadata['document_url'])
        
        # íŒŒì‹±
        parsed = parser.parse_ixbrl_10k(html)
        
        # ì €ì¥
        parser.save_parsed_10k('TSLA', metadata, parsed)
        
        print(f"\nğŸ‰ TSLA 10-K ì™„ì „ ìˆ˜ì§‘ ì„±ê³µ!")
    else:
        print("\nâŒ TSLA 10-K ì°¾ê¸° ì‹¤íŒ¨")

