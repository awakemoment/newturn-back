"""
ì¢…í•© íŒŒì„œ v3

ì „ëµ:
1. Item 1 (Business) - ê²½ìŸ í™˜ê²½, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
2. Item 1A (Risk) - ë¦¬ìŠ¤í¬ ìš”ì¸
3. Item 7 (MD&A) - ê²½ì˜ì§„ ë¶„ì„, ì „ë§

ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¥˜:
- ê²½ìŸì‚¬ ê´€ë ¨
- ê³µê¸‰ë§ ê´€ë ¨
- ê·œì œ/ì§€ì •í•™ ê´€ë ¨
- ì‹ ì œí’ˆ ê´€ë ¨
- ì¬ë¬´ ì „ë§ ê´€ë ¨
"""
import re
import json


class ComprehensiveParser:
    """ì¢…í•© íŒŒì„œ"""
    
    def __init__(self, ticker):
        self.ticker = ticker
        self.company_names = self.get_company_names(ticker)
    
    def get_company_names(self, ticker):
        """íšŒì‚¬ëª… ë§¤í•‘ (ìê¸° íšŒì‚¬ ì œì™¸ìš©)"""
        
        mapping = {
            'AAPL': ['Apple', 'Apple Inc'],
            'META': ['Meta', 'Meta Platforms', 'Facebook'],
            'NVDA': ['NVIDIA', 'Nvidia'],
            'AMZN': ['Amazon', 'Amazon.com'],
            'TSLA': ['Tesla', 'Tesla Inc'],
            'GOOGL': ['Google', 'Alphabet'],
            'MSFT': ['Microsoft'],
        }
        
        return mapping.get(ticker, [ticker])
    
    def split_into_sentences(self, text):
        """ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬"""
        
        # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬ (. ! ? ê¸°ì¤€)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
        return [s.strip() for s in sentences if len(s) > 50]
    
    def classify_sentence(self, sentence):
        """ë¬¸ì¥ ë¶„ë¥˜"""
        
        categories = []
        sentence_lower = sentence.lower()
        
        # 1. ê²½ìŸ ê´€ë ¨
        if any(word in sentence_lower for word in ['compet', 'rival', 'market share', 'versus', 'compared to']):
            categories.append('competition')
        
        # 2. ê³µê¸‰ë§ ê´€ë ¨
        if any(word in sentence_lower for word in ['supplier', 'supply chain', 'manufacture', 'source', 'procurement']):
            categories.append('supply_chain')
        
        # 3. ê·œì œ/ì§€ì •í•™
        if any(word in sentence_lower for word in ['regulation', 'tariff', 'sanction', 'export control', 'china', 'geopolitical']):
            categories.append('regulatory')
        
        # 4. ì‹ ì œí’ˆ/í˜ì‹ 
        if any(word in sentence_lower for word in ['launch', 'introduce', 'new product', 'innovation', 'development']):
            categories.append('innovation')
        
        # 5. ì¬ë¬´ ì „ë§
        if any(word in sentence_lower for word in ['expect', 'anticipate', 'guidance', 'forecast', 'project', 'plan to']):
            categories.append('forward_looking')
        
        # 6. ë¦¬ìŠ¤í¬
        if any(word in sentence_lower for word in ['risk', 'uncertainty', 'challenge', 'threat', 'concern']):
            categories.append('risk')
        
        # 7. ê³ ê°/ì‹œì¥
        if any(word in sentence_lower for word in ['customer', 'market', 'demand', 'adoption']):
            categories.append('market')
        
        return categories
    
    def is_valuable_sentence(self, sentence):
        """ê°€ì¹˜ìˆëŠ” ë¬¸ì¥ì¸ê°€?"""
        
        # ìˆ«ì í¬í•¨ (%, $, ì—°ë„)
        has_numbers = bool(re.search(r'\d+%|\$\d+|202\d|Q[1-4]', sentence))
        
        # êµ¬ì²´ì  ì´ë¦„ í¬í•¨
        has_proper_nouns = bool(re.search(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', sentence))
        
        # ìê¸° íšŒì‚¬ëª…ë§Œ ë‚˜ì˜¤ëŠ” ê±´ ì œì™¸
        only_self = all(name in sentence for name in self.company_names) and len(re.findall(r'\b[A-Z][a-z]+', sentence)) <= 3
        
        return (has_numbers or has_proper_nouns) and not only_self
    
    def extract_from_section(self, section_name):
        """ì„¹ì…˜ì—ì„œ ì¶”ì¶œ"""
        
        try:
            with open(f'data/section_{self.ticker}_{section_name}.txt', 'r', encoding='utf-8') as f:
                text = f.read()
        except FileNotFoundError:
            return {}
        
        sentences = self.split_into_sentences(text)
        
        categorized = {
            'competition': [],
            'supply_chain': [],
            'regulatory': [],
            'innovation': [],
            'forward_looking': [],
            'risk': [],
            'market': [],
        }
        
        for sentence in sentences[:1000]:  # ìµœëŒ€ 1000ë¬¸ì¥
            
            # ê°€ì¹˜ìˆëŠ” ë¬¸ì¥ë§Œ
            if not self.is_valuable_sentence(sentence):
                continue
            
            # ë¶„ë¥˜
            categories = self.classify_sentence(sentence)
            
            # ê° ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€
            for category in categories:
                if category in categorized and len(categorized[category]) < 20:  # ê° ì¹´í…Œê³ ë¦¬ ìµœëŒ€ 20ê°œ
                    categorized[category].append({
                        'sentence': sentence,
                        'section': section_name,
                        'length': len(sentence)
                    })
        
        return categorized
    
    def parse_all(self):
        """ì „ì²´ íŒŒì‹±"""
        
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ {self.ticker} ì¢…í•© íŒŒì‹±")
        print('-'*80)
        
        results = {
            'ticker': self.ticker,
            'sections': {}
        }
        
        # 3ê°œ ì„¹ì…˜ ëª¨ë‘ íŒŒì‹±
        for section in ['item_1_business', 'item_1a_risk_factors', 'item_7_mda']:
            print(f"   ğŸ“„ {section} íŒŒì‹± ì¤‘...")
            
            categorized = self.extract_from_section(section)
            
            total = sum(len(v) for v in categorized.values())
            print(f"      âœ… {total}ê°œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ")
            
            results['sections'][section] = categorized
        
        # ì „ì²´ í†µê³„
        all_categories = {}
        for section_data in results['sections'].values():
            for category, items in section_data.items():
                if category not in all_categories:
                    all_categories[category] = []
                all_categories[category].extend(items)
        
        results['summary'] = {
            category: len(items)
            for category, items in all_categories.items()
        }
        
        print(f"\n   ğŸ“Š ì „ì²´ ìš”ì•½:")
        for category, count in results['summary'].items():
            if count > 0:
                print(f"      {category}: {count}ê°œ")
        
        return results


def parse_all_stocks(tickers):
    """ëª¨ë“  ì¢…ëª© íŒŒì‹±"""
    
    print("="*80)
    print("ğŸ¯ ì¢…í•© íŒŒì„œ v3 - ì „ì²´ ì„¹ì…˜ ë¶„ì„")
    print("="*80)
    print()
    print("ì „ëµ:")
    print("  âœ… Item 1, 1A, 7 ëª¨ë‘ í™œìš©")
    print("  âœ… ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¥˜")
    print("  âœ… ìê¸° íšŒì‚¬ëª… ì œì™¸")
    print("  âœ… ìˆ«ì/ê³ ìœ ëª…ì‚¬ í¬í•¨ ë¬¸ì¥ë§Œ")
    print()
    
    all_results = {}
    
    for ticker in tickers:
        parser = ComprehensiveParser(ticker)
        result = parser.parse_all()
        all_results[ticker] = result
    
    # ì €ì¥
    with open('data/comprehensive_insights.json', 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*80}")
    print("âœ… ì €ì¥: data/comprehensive_insights.json")
    print("="*80)
    
    # ì „ì²´ í†µê³„
    print(f"\n{'='*80}")
    print("ğŸ“Š ì „ì²´ í†µê³„")
    print('='*80)
    
    for ticker, data in all_results.items():
        total = sum(data['summary'].values())
        print(f"\n{ticker}: {total}ê°œ ì¸ì‚¬ì´íŠ¸")
        
        for category, count in sorted(data['summary'].items(), key=lambda x: -x[1]):
            if count > 0:
                print(f"  {category}: {count}ê°œ")
    
    return all_results


if __name__ == "__main__":
    STOCKS = ['AAPL', 'META', 'NVDA', 'AMZN', 'TSLA']
    
    results = parse_all_stocks(STOCKS)
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\n{'='*80}")
    print("ğŸ“‹ ìƒ˜í”Œ ì¸ì‚¬ì´íŠ¸ (AAPL)")
    print('='*80)
    
    if 'AAPL' in results:
        aapl = results['AAPL']
        
        # Item 1 ê²½ìŸ ê´€ë ¨
        item1 = aapl['sections'].get('item_1_business', {})
        competition = item1.get('competition', [])
        
        if competition:
            print(f"\nğŸ” ê²½ìŸ í™˜ê²½ (Item 1):")
            for item in competition[:3]:
                print(f"  - {item['sentence'][:150]}...")
        
        # Item 7 ì „ë§
        item7 = aapl['sections'].get('item_7_mda', {})
        forward = item7.get('forward_looking', [])
        
        if forward:
            print(f"\nğŸ”® ê²½ì˜ì§„ ì „ë§ (Item 7):")
            for item in forward[:3]:
                print(f"  - {item['sentence'][:150]}...")
    
    print(f"\n{'='*80}")
    print("ğŸ’¡ ì´ì œ ëª¨ë“  ì„¹ì…˜ì—ì„œ ì²´ê³„ì  ì¶”ì¶œ!")
    print("="*80)

